# Файн-тюнинг с добавлением LoRa-адаптеров и дообучение LLM-модели

<!-- Provide a quick summary of what the model is/does. -->

Ссылка на модель: https://huggingface.co/GlebShevtsov/tlite-ft-gguf

Учебный проект. \
Дообученная и квантизированная с Lora-адаптерами модель [T-lite](https://huggingface.co/AnatoliiPotapov/T-lite-instruct-0.1) на собственном датасете, для вычленения ключевой информации о деятельности контрагента по описанию с собственного сайта контрагента.

## Dataset

Для обучения был использован собственный датасет очищенных текстов с сайтов контрагентов об описании их деятельности и вручную созданные краткие описания деятельности.\
Чтобы модель не потеряла изначальный функционал помимо собственного датасета был также использован [alpaca датасет](https://huggingface.co/datasets/freQuensy23/ru-alpaca-cleaned)

## Evaluation

Для измерения производительности модели использовались метрики семейства [rouge](https://huggingface.co/spaces/evaluate-metric/rouge).\
Дообученная модель сравнивалась с базовой стратегией (брать первые предложения из текста с сайта контрагента в разделе "о компании")

|               | rouge1 | rougeL | rougeLsum |
| :--- | :---: | :---: | :---: |
| Baseline | 6.19 | 6.18 | 6.12 |
| T-lite без дообучения | 5.50 | 5.53 | 5.57 |
| T-lite fine-tuned | 7.53 | 7.50 | 7.47 |

Таким образом модель показала лучшие результаты, чем без дообучения и чем базовая стратегия.

## Examples of usage

Для запуска квантизированной модели нужно установить llama-cpp

```
pip install llama-cpp-python
```
Далее можно использовать стандартный пайплайн
```python
from llama_cpp import Llama

llm = Llama.from_pretrained(
    repo_id="SanyaP4elkin/tlite-ft-gguf",
    filename="*tlite-ft-model-Q4_K_M.gguf",
    verbose=False
)

comp_descr = input()

output = llm(
    f"Q: По тексту с сайта компании вкратце опиши, чем она занимается\n{comp_descr}",
    max_tokens = 1000
)

print(output)
```

# MarketAdvClassification
## Классификация объявлений с сайта объявлений с помощью NLP и CV моделей

В данной работе я спарсил данные объявлений с сайта с объявлениями о продаже товаров и услуг, а именно следующие данные: изображение (первое фото в объявлении), уникальный id, текст объявления и цену. Общее количество полученных объявлений >27 тысяч, из них >22 тысяч с изображениями, всего 17 категорий-классов объявлений. \
Классы объявлений несбалансированы, поэтому я построил два кастомных датасета (для изображений и для изображений и текста) и взвешенный семплер.\
На полученных объявлениях с изображениями я построил базовую модель для классификации изображений с помощью PyTorch, а затем  применил предобученные модели из pytorch-vision (Resnet50, EfficientNet). Также я попробовал сравнить качество модели с использованием аугментации и без. Итоговое значение лучшей модели на объявлениях с изображениями из валидационной выборки находится ниже в таблице. \
Затем я применил fine-tuned модель RuBERT и rubert-tiny2 к текстам объявлений. Текста объявлений были предварительно очищены от лишних символов и стоп-слов и токенизированы с помощью соответствующих токенайзеров. Результат лучшей модели на основе текстовых данных объявлений из валидационной выборки также находится ниже в таблице. \
Для увеличения качества результата я решил объединить модели с помощью использованных извлеченных признаков моделей, для этого я построил кастомный датасет и нейронную сеть использующую фичи моделей. Т.к. качество этой модели оказалось достаточно низким я решил объединить фичи моделей с помощью моделей классического обучения (логистическая регрессия, KNN, случайный лес) и добился качества >0.99 F1 \
Качество моделей: 
| Модель | F1-macro | Accuracy |
| --- | --- | --- |
| EfficientNet (на изображениях) | 0.915080	| 0.941207 |
| resnet50X	(на изображениях) | 0.892389	| 0.921956 |
| EfficientNet + albumentation (на изображениях) | 0.8716	| 0.9069 |
| rubert-tiny2 | 0.872 | 0.9416 |
| EffNet + rubert-tiny2 | 0.421072 | 0.606042 |
| RandomForest + EffNet + rubert-tiny2 | 0.375960	| 0.651032 | 
| KNN (15 neigh) + EffNet + rubert-tiny2 | 0.954844 |	0.967167 |	
| LogReg + EffNet + rubert-tiny2 | 0.991412 | 0.993619 | 

Использованные библиотеки: `PyTorch` для написания моделей и оформления датасетов, `Py-Lightning` для обучения моделей, `albumentation` для добавления аугментации, `HuggingFace` `Transformers` для построения NLP моделей и обучения, `sklearn` для моделей классического обучения в объединеннии признаков моделей, `wandb` для логгирования обучения и состояний моделей, `ntlk` для препроцессинга текста и т.д.

# Metrics
## Анализ бизнес-показателей приложения
Анализ данных приложения и рассчет метрик LTV, CAC, ROMI, Retention и т.д..

# PowerBI
## Отчет о показателях популярных телеграм каналов в PowerBI
Статистика некоторых самых популярных открытых телеграм каналов и постов в них. Данные были получены с помощью python через API телеграма, каналы были выбраны с помощью данных tgstats

# SentimentMarketplace
## Сбор и анализ сентимента отзывов с маркетплейса

В данной работе я спарсил отзывы с маркетплейса по некоторым запросам в общем количестве >220 тысяч, хотя парсер позволяет собрать намного больше. \
Текст объявлений был очищен от лишних символов, оскорблений и был стеммизирован. Классы сентимента были несбалансированы, т.к. положительных отзывов оказалось в >15 раз больше, чем нейтральных или отрицательных, поэтому для обучения был применен кастовый датасет и взвешенный семплер. \
На основе этих данных был проведен анализ сентимента с использованием претренированной модели rubert-tiny2. \
Основные использованные библиотеки: `HuggingFace` для получения модели и токенайзера, `Pytorch` для построения кастомного датасета и циклов обучения и `Wandb` для логирования процесса обучения и сохранения состояний модели.

# ABtesting

Решение заданий на применение АБ тестирования

# SpbMsk
## Анализ рынка недвижимости в Москве и Санкт-Петербурге

Разведочный анаиз данных, применение алгоритмов и проверка гипотез
